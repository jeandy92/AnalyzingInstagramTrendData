{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Instagram trend data\n",
    "\n",
    "## Our analysis subjects:\n",
    "\n",
    "1. The most profiles per city?\n",
    "2. The most posts per city?\n",
    "3. The most posts per profile?\n",
    "4. The most likes per profile?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publicacao de alteracao\n",
    "\n",
    "1. git add .\\InstagramIndexes.ipynb\n",
    "2. git commit -m \"Mensagem do commit\"\n",
    "3. git status \n",
    "4. git push -u origin master"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando versão python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versao da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versao da Linguagem Python Usada neste Jupyter Notebook', python_version())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particionando arquivo posts \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "# caminho do arquivo grande\n",
    "file_path = r'E:\\Kaggle\\input\\Instagram\\instagram_posts.csv'\n",
    "\n",
    "# tamanho de cada arquivo menor em bytes\n",
    "chunk_size = 10000000\n",
    "\n",
    "# abrir arquivo grande em modo texto\n",
    "with open(file_path, 'r', newline='', encoding='utf-8') as f:\n",
    "    # criar leitor CSV\n",
    "    reader = csv.reader(f)\n",
    "    # ler cabeçalho\n",
    "    header = next(reader)\n",
    "    # inicializar contador de chunk\n",
    "    chunk_num = 0\n",
    "    while True:\n",
    "        # ler chunk do arquivo\n",
    "        chunk = ''\n",
    "        current_size = 0\n",
    "        for row in reader:\n",
    "            row_str = ','.join(row) + '\\n'\n",
    "            row_size = len(row_str.encode('utf-8'))\n",
    "            if current_size + row_size > chunk_size:\n",
    "                break\n",
    "            chunk += row_str\n",
    "            current_size += row_size\n",
    "        else:\n",
    "            # fim do arquivo, sair do loop\n",
    "            if not chunk:\n",
    "                break\n",
    "        # nome do arquivo de chunk\n",
    "        chunk_name = f'{os.path.splitext(file_path)[0]}_{chunk_num}.csv'\n",
    "        # criar arquivo de chunk e escrever cabeçalho e chunk nele\n",
    "        with open(chunk_name, 'w', newline='', encoding='utf-8') as chunk_file:\n",
    "            writer = csv.writer(chunk_file)\n",
    "            writer.writerow(header)\n",
    "            chunk_file.write(chunk)\n",
    "        # incrementar contador de chunk\n",
    "        chunk_num += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando dataframes e definindo schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando o módulo csv\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from decimal import Decimal\n",
    "\n",
    "def location_schema():\n",
    "    schema = pd.DataFrame({\n",
    "        \"sid\": pd.Series(dtype=\"Int64\"),\n",
    "        \"id\": pd.Series(dtype=\"Int64\"),\n",
    "        \"name\": pd.Series(dtype=\"string\"),\n",
    "        \"street\": pd.Series(dtype=\"string\"),\n",
    "        \"zip\": pd.Series(dtype=\"string\"),\n",
    "        \"city\": pd.Series(dtype=\"string\"),\n",
    "        \"region\": pd.Series(dtype=\"string\"),\n",
    "        \"cd\": pd.Series(dtype=\"string\"),\n",
    "        \"phone\": pd.Series(dtype=\"string\"),\n",
    "        \"aj_exact_city_match\": pd.Series(dtype=\"string\"),\n",
    "        \"aj_exact_country_match\": pd.Series(dtype=\"string\"),\n",
    "        \"blurb\": pd.Series(dtype=\"string\"),\n",
    "        \"dir_city_id\": pd.Series(dtype=\"string\"),\n",
    "        \"dir_city_name\": pd.Series(dtype=\"string\"),\n",
    "        \"dir_city_slug\": pd.Series(dtype=\"string\"),\n",
    "        \"dir_country_id\": pd.Series(dtype=\"string\"),\n",
    "        \"dir_country_name\": pd.Series(dtype=\"string\"),\n",
    "        \"lat\": pd.Series(dtype=\"string\"),\n",
    "        \"lng\": pd.Series(dtype=\"string\"),\n",
    "        \"primary_alias_on_fb\": pd.Series(dtype=\"string\"),\n",
    "        \"slug\": pd.Series(dtype=\"string\"),\n",
    "        \"website\": pd.Series(dtype=\"string\"),\n",
    "        \"cts\": pd.Series(dtype=\"string\")\n",
    "    })\n",
    "    return schema\n",
    "\n",
    "def profile_schema():\n",
    "    schema = pd.DataFrame({\n",
    "        \"sid\": pd.Series(dtype=\"Int64\"),\n",
    "        \"profile_id\": pd.Series(dtype=\"Int64\"),\n",
    "        \"profile_name\": pd.Series(dtype=\"string\"),\n",
    "        \"firstname_lastname\": pd.Series(dtype=\"string\"),\n",
    "        \"description\": pd.Series(dtype=\"string\"),\n",
    "        \"following\": pd.Series(dtype=\"string\"),\n",
    "        \"followers\": pd.Series(dtype=\"string\"),\n",
    "        \"n_posts\": pd.Series(dtype=\"string\"),\n",
    "        \"url\": pd.Series(dtype=\"string\"),\n",
    "        \"cts\": pd.Series(dtype=\"string\"),\n",
    "        \"is_business_account\": pd.Series(dtype=\"string\")\n",
    "    })\n",
    "    return schema\n",
    "\n",
    "def post_schema():\n",
    "    schema = pd.DataFrame({\n",
    "        \"sid\": pd.Series(dtype=\"Int64\"),\n",
    "        \"sid_profile\": pd.Series(dtype=\"string\"),\n",
    "        \"post_id\": pd.Series(dtype=\"string\"),\n",
    "        \"profile_id\": pd.Series(dtype=\"string\"),\n",
    "        \"location_id\": pd.Series(dtype=\"string\"),\n",
    "        \"cts\": pd.Series(dtype=\"string\"),\n",
    "        \"post_type\": pd.Series(dtype=\"string\"),\n",
    "        \"description\": pd.Series(dtype=\"string\"),\n",
    "        \"numbr_likes\": pd.Series(dtype=\"string\"),\n",
    "        \"number_comments\": pd.Series(dtype=\"string\")\n",
    "    })\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o processamento do arquivo E:\\Kaggle\\input\\Instagram\\instagram_locations.csv....\n",
      "Arquivo processado com sucesso....\n",
      "Iniciando o processamento do arquivo E:\\Kaggle\\input\\Instagram\\instagram_profiles.csv....\n",
      "Arquivo processado com sucesso....\n",
      "Iniciando o processamento do arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv....\n",
      "Arquivo processado com sucesso....\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 10000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 20000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 30000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 40000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 50000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 60000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 70000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 80000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 90000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 100000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 110000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 120000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 130000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 140000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 150000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 160000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 170000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 180000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 190000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 200000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 210000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 220000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 230000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 240000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 250000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 260000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 270000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 280000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 290000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 300000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 310000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 320000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 330000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 340000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 350000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 360000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 370000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 380000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 390000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 400000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 410000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 420000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Processando os dados.... Arquivo E:\\Kaggle\\input\\Instagram\\instagram_posts.csv\n",
      "Criando chunk... 430000\n",
      "Agrupando posts por cidade...\n",
      "Agrupando posts por Perfis...\n",
      "Dados de cidade agrupados\n",
      "                             qtd_posts  qtd_likes  qtd_comments\n",
      "location_id       post_type                                    \n",
      "10150150725405712 1                 29       6223           210\n",
      "5082122005225411  1                 26       3279           174\n",
      "2826522444240181  2                  1         21             1\n",
      "                  1                 30       3534           293\n",
      "2806221269517102  2                  5         77             6\n",
      "                       qtd_posts  qtd_likes  qtd_comments\n",
      "profile_id  post_type                                    \n",
      "14237712262 1                  1         44             1\n",
      "14235400795 1                  1          0             0\n",
      "14235344553 2                  1          2             0\n",
      "14234720132 1                  1          8             1\n",
      "14232760274 1                  1          0             0\n"
     ]
    }
   ],
   "source": [
    "#Reading csv and put the information inside of data frame \n",
    "#profile_file = r'E:\\Kaggle\\input\\Instagram\\instagram_profiles.csv'\n",
    "#cities_file  = r'E:\\Kaggle\\input\\Instagram\\instagram_locations.csv'\n",
    "posts_file   = r'E:\\Kaggle\\input\\Instagram\\instagram_posts.csv'\n",
    "ec = 'latin'\n",
    "delimiter = '\\t'\n",
    "\n",
    "print(f\"Iniciando o processamento do arquivo {cities_file}....\")\n",
    "df_cities   = pd.read_csv(cities_file\n",
    ",delimiter=delimiter\n",
    ",encoding=ec)\n",
    "print(\"Arquivo processado com sucesso....\")\n",
    "\n",
    "print(f\"Iniciando o processamento do arquivo {profile_file}....\")\n",
    "df_profiles = pd.read_csv(profile_file\n",
    ",delimiter=delimiter\n",
    ",encoding=ec)\n",
    "print(\"Arquivo processado com sucesso....\")\n",
    "\n",
    "print(f\"Iniciando o processamento do arquivo {posts_file}....\")\n",
    "df_posts = pd.DataFrame()\n",
    "df_cities_posts = pd.DataFrame()\n",
    "df_profile_posts = pd.DataFrame()\n",
    "\n",
    "count = 0\n",
    "print(\"Arquivo processado com sucesso....\")\n",
    "\n",
    "for df_post_part in pd.read_csv( posts_file\n",
    "    ,delimiter=delimiter #delimter\n",
    "    ,encoding=ec #encoding\n",
    "    ,error_bad_lines=False #Exlude badlines\n",
    "    ,names=['sid','sid_profile','post_id','profile_id','location_id','cts','post_type','description','numbr_likes','number_comments'] \n",
    "    ,header=0#header\n",
    "    ,quotechar='\"'\n",
    "    ,chunksize=1000000 #Leitura de arquivo particionado,quantidade de linhas\n",
    "    #,dtype=post_schema() #Aplica scheam\n",
    "    ):\n",
    "    \n",
    "    count = count + 10000\n",
    "    \n",
    "    print(f\"Processando os dados.... Arquivo {posts_file}\")\n",
    "    print(f\"Criando chunk... {count}\")\n",
    "    df_post_part = df_post_part.astype(post_schema().dtypes) #Aplica o schema em cada pedaco(chunk do arquivo)\n",
    "    df_post_part = df_post_part.dropna(subset=['numbr_likes'])\n",
    "    df_post_part = df_post_part.dropna(subset=['number_comments'])\n",
    "    \n",
    "    #print(\"Convertendo as colunas para sumarizacao.....\")\n",
    "    df_post_part['numbr_likes'] =  df_post_part['numbr_likes'].astype(float)\n",
    "    df_post_part['number_comments'] =  df_post_part['number_comments'].astype(float)\n",
    "    df_post_part['numbr_likes'] = df_post_part['numbr_likes'].apply(lambda x: int(round(x)))\n",
    "    df_post_part['number_comments'] = df_post_part['number_comments'].apply(lambda x: int(round(x)))\n",
    "    #Removendo linhas nulas para realizar o relacionamento\n",
    "    #Observe que o parâmetro errors='coerce' é usado no método to_numeric(). \n",
    "    # Isso faz com que os valores que não puderem ser convertidos em números sejam convertidos em NaN\n",
    "    #df_posts['sid'] = pd.to_numeric(df_posts['sid'],errors='coerce') \n",
    "    \n",
    "    \n",
    "    df_post_part['location_id'] = pd.to_numeric(df_post_part['location_id'],errors='coerce') \n",
    "    df_post_part['profile_id'] =  pd.to_numeric(df_post_part['profile_id'],errors='coerce') \n",
    "    df_post_part['location_id'] = df_post_part['location_id'].apply(Decimal)\n",
    "    df_post_part['profile_id'] = df_post_part['profile_id'].apply(Decimal)\n",
    "    \n",
    "    df_post_part = df_post_part.dropna(subset=['location_id'])\n",
    "    #print(\"Colunas convertidas com sucesso..\")\n",
    "    #print(\"Concatenando Data Frames.... \")\n",
    "    df_cities_posts = pd.concat([df_cities_posts,df_post_part])# Reune todos os pedacos no data frame principal\n",
    "        \n",
    "    print(\"Agrupando posts por cidade...\")\n",
    "    df_cities_posts = df_post_part.groupby(['location_id','post_type']).agg({'post_id':'count','numbr_likes':'sum','number_comments':'sum'})\n",
    "    df_cities_posts = df_cities_posts.sort_values(by='location_id', ascending =False).rename(columns={'location_id':'id','post_id':'qtd_posts','numbr_likes':'qtd_likes','number_comments':'qtd_comments'})\n",
    "    df_profile_posts = pd.concat([df_profile_posts,df_post_part])# Reune todos os pedacos no data frame principal\n",
    "    \n",
    "    print(\"Agrupando posts por Perfis...\")\n",
    "    df_profile_posts = df_post_part.groupby(['profile_id','post_type']).agg({'post_id':'count','numbr_likes':'sum','number_comments':'sum'})\n",
    "    df_profile_posts = df_profile_posts.sort_values(by='profile_id', ascending =False).rename(columns={'profile_id':'id','post_id':'qtd_posts','numbr_likes':'qtd_likes','number_comments':'qtd_comments'})\n",
    "\n",
    "    \n",
    "    \n",
    "print(\"Dados de cidade agrupados\")\n",
    "print(df_cities_posts.head())\n",
    "print(df_profile_posts.head())\n",
    "\n",
    "# salvar o DataFrame como arquivo CSV com SOH como delimitador\n",
    "df_cities_posts.to_csv('E:\\Kaggle\\output\\TheMostPostsPerCityGroup.csv',sep='\\x01')\n",
    "df_profile_posts.to_csv('E:\\Kaggle\\output\\TheMostPostsPerProfileGroup.csv',sep='\\x01')\n",
    "\n",
    "\n",
    "    #df_profiles_posts\n",
    "    #df_cities.groupby('city').agg({'id':'count'})\n",
    "    #df_posts = pd.concat([df_posts,df_post_part])# Reune todos os pedacos no data frame principal\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando schema nos dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Only a column name can be used for the key in a dtype mappings argument.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32me:\\Projetos\\EngenhariaDeDados\\InstagramProject\\InstagramIndexes.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projetos/EngenhariaDeDados/InstagramProject/InstagramIndexes.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_cities \u001b[39m=\u001b[39m df_cities\u001b[39m.\u001b[39mastype(location_schema()\u001b[39m.\u001b[39mdtypes)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projetos/EngenhariaDeDados/InstagramProject/InstagramIndexes.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_profiles \u001b[39m=\u001b[39m df_profiles\u001b[39m.\u001b[39mastype(profile_schema()\u001b[39m.\u001b[39mdtypes)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Projetos/EngenhariaDeDados/InstagramProject/InstagramIndexes.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_posts \u001b[39m=\u001b[39m df_posts\u001b[39m.\u001b[39;49mastype(post_schema()\u001b[39m.\u001b[39;49mdtypes)\n",
      "File \u001b[1;32mc:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:5851\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5849\u001b[0m \u001b[39mfor\u001b[39;00m col_name \u001b[39min\u001b[39;00m dtype\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m   5850\u001b[0m     \u001b[39mif\u001b[39;00m col_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m-> 5851\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[0;32m   5852\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mOnly a column name can be used for the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   5853\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mkey in a dtype mappings argument.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   5854\u001b[0m         )\n\u001b[0;32m   5855\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[0;32m   5856\u001b[0m \u001b[39mfor\u001b[39;00m col_name, col \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems():\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Only a column name can be used for the key in a dtype mappings argument.'"
     ]
    }
   ],
   "source": [
    "df_cities = df_cities.astype(location_schema().dtypes)\n",
    "df_profiles = df_profiles.astype(profile_schema().dtypes)\n",
    "df_posts = df_posts.astype(post_schema().dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The most profiles per city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QTD_PROFILES</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New York, New York</th>\n",
       "      <td>29954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moscow, Russia</th>\n",
       "      <td>21087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London, United Kingdom</th>\n",
       "      <td>20251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saint Petersburg, Russia</th>\n",
       "      <td>8636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles, California</th>\n",
       "      <td>7175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          QTD_PROFILES\n",
       "city                                  \n",
       "New York, New York               29954\n",
       "Moscow, Russia                   21087\n",
       "London, United Kingdom           20251\n",
       "Saint Petersburg, Russia          8636\n",
       "Los Angeles, California           7175"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_group = df_cities.groupby('city').agg({'id':'count'})\n",
    "city_group = city_group.sort_values(by='id', ascending =False).rename(columns={'id':'QTD_PROFILES','city':'CITY'})\n",
    "\n",
    "# salvar o DataFrame como arquivo CSV com SOH como delimitador\n",
    "#df.to_csv('exemplo.csv', sep='\\x01', index=False)\n",
    "city_group.to_csv('E:\\Kaggle\\output\\TheMostProfilesPerCity.csv',sep='\\x01')\n",
    "\n",
    "city_group.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The most posts per city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "The most posts per city\n",
      "*************************\n",
      "                                             city  qtd_posts  qtd_likes  \\\n",
      "40866                                      Soroca         50       2232   \n",
      "38850                 Comrat, GÄgÄuzia, Moldova         48       1992   \n",
      "43523                          New York, New York         45       2872   \n",
      "30891  Tiraspolul Nou, StÃ®nga Nistrului, Moldova         42       1149   \n",
      "39768                 Centru, ChiÅinÄu, Moldova         41       1531   \n",
      "...                                           ...        ...        ...   \n",
      "33164                           Chisinau, Moldova          1         42   \n",
      "33170                          Brooklyn, New York          1         43   \n",
      "8121                      Victorville, California          1         60   \n",
      "8117                     Nagoya-shi, Aichi, Japan          1        386   \n",
      "24712                                Aosta, Italy          1        113   \n",
      "\n",
      "       qtd_comments  \n",
      "40866            88  \n",
      "38850            33  \n",
      "43523           227  \n",
      "30891            19  \n",
      "39768            32  \n",
      "...             ...  \n",
      "33164             0  \n",
      "33170             4  \n",
      "8121              3  \n",
      "8117             30  \n",
      "24712             1  \n",
      "\n",
      "[49424 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Fazendo join pelo location_id\n",
    "print(\"*\"*25)\n",
    "print(\"The most posts per city\")\n",
    "print(\"*\"*25)\n",
    "merged_df = pd.merge(df_cities_posts,df_cities, left_on='location_id', right_on='id')\n",
    "print(merged_df[['city','qtd_posts','qtd_likes','qtd_comments']].sort_values(by='qtd_posts', ascending =False))\n",
    "\n",
    "# salvar o DataFrame como arquivo CSV com SOH como delimitador\n",
    "merged_df.to_csv('E:\\Kaggle\\output\\TheMostPostsPerCity.csv',sep='\\x01')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The most posts per profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "The most posts per profile\n",
      "**************************************************\n",
      "                        profile_name  qtd_posts  qtd_likes  qtd_comments\n",
      "12446               wellnessacademie         38       1914            91\n",
      "14276                 propertpix_ltd         34        631            17\n",
      "22982                        balesii         32        230            11\n",
      "9572   therapeutic.massage.northwich         32        465             3\n",
      "17304                    writopialab         31       1175            43\n",
      "...                              ...        ...        ...           ...\n",
      "16879       thompsonbrotherslacrosse          1       1162             2\n",
      "16880                   ilopushynska          1        139             1\n",
      "16881                      ragnabley          1        170             5\n",
      "16882                tvscalumstewart          1         12             0\n",
      "22373                  sweet.lanaaaa          1        518             4\n",
      "\n",
      "[44746 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*50)\n",
    "print(\"The most posts per profile\")\n",
    "print(\"*\"*50)\n",
    "merged_df = pd.merge(df_profile_posts,df_profiles, left_on='profile_id', right_on='profile_id')\n",
    "df_posts_profile = merged_df[['profile_name','qtd_posts','qtd_likes','qtd_comments']].sort_values(by='qtd_posts', ascending =False)\n",
    "print(merged_df[['profile_name','qtd_posts','qtd_likes','qtd_comments']].sort_values(by='qtd_posts', ascending =False))\n",
    "\n",
    "# salvar o DataFrame como arquivo CSV com SOH como delimitador\n",
    "df_posts_profile.to_csv('E:\\Kaggle\\output\\TheMostPostsPerProfile.csv',sep='\\x01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir o arquivo\n",
    "with open('E:\\Kaggle\\input\\Instagram\\instagram_posts.csv', 'r') as f:\n",
    "    # contar o número de linhas\n",
    "    num_linhas = sum(1 for linha in f)\n",
    "\n",
    "# imprimir o número de linhas\n",
    "print(f'O arquivo tem {num_linhas} linhas.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6014c9712583ffa1822ae00666c29beffde09c2795b53b866bbae53c79cb846"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
